{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Data Sci Eng Methods</h1>\n",
        "<h3>Assignment 1 â€“ ML Data Cleaning and Feature Selection</h3>\n",
        "<h4>Data Set</h4>\n",
        "<a href=\"https://www.kaggle.com/datasets/rohanrao/nifty50-stock-market-data\">NIFTY-50 Stock Market Data (2000 - 2021)</a>\n",
        "<h5>About Dataset</h5>\n",
        "<p>The data is the price history and trading volumes of the fifty stocks in the index NIFTY 50 from NSE (National Stock Exchange) India. All datasets are at a day-level with pricing and trading values split across .cvs files for each stock along with a metadata file with some macro-information about the stocks itself. The data spans from 1st January, 2000 to 30th April, 2021.</p>\n",
        "Note: The dataset contains stock data for 50 stocks\n",
        "\n",
        "<h5>Columns</h5>\n",
        "\n",
        "Date - Trade Data\n",
        "\n",
        "Symbol - Name of stock\n",
        "\n",
        "Series - Type of security\n",
        "\n",
        "Prev Close - Previous data closing price\n",
        "\n",
        "Open - Opening price for the day\n",
        "\n",
        "High - Highest price for the day\n",
        "\n",
        "Low - Lowest price for the day\n",
        "\n",
        "Last - Last trade price\n",
        "\n",
        "Closes - Closing price\n",
        "\n",
        "VWAP - Volume-weighted average price (a ratio of the cumulative share price to the cumulative volume traded over a given time period)\n",
        "\n",
        "Volume - volume trades for the day\n",
        "\n",
        "Turnover - The turnover ratio is ratio of sellers to buyers of a stock\n",
        "\n",
        "Trades - Number of Trades\n",
        "\n",
        "Deliverable Volume - Amount of deliverable volume\n",
        "\n",
        "%Deliverble - Percentage of shares that were delivered\n",
        "\n",
        "Note: All price are in Rupees\n",
        "\n",
        "<h3>Aim:</h3>\n",
        "\n",
        "* What are the data types? (Only numeric and categorical)\n",
        "\n",
        "* Are there missing values?\n",
        "\n",
        "* What are the likely distributions of the numeric variables?\n",
        "\n",
        "* Which independent variables are useful to predict a target (dependent variable)? (Use at least three methods)\n",
        "\n",
        "* Which independent variables have missing data? How much?\n",
        "\n",
        "* Do the training and test sets have the same data?\n",
        "\n",
        "* In the predictor variables independent of all the other predictor variables?\n",
        "\n",
        "* Which predictor variables are the most important?\n",
        "\n",
        "* Do the ranges of the predictor variables make sense?\n",
        "\n",
        "* What are the distributions of the predictor variables?   \n",
        "\n",
        "* Remove outliers and keep outliers (does if have an effect of the final predictive model)?\n",
        "\n",
        "* Remove 1%, 5%, and 10% of your data randomly and impute the values back using at least 3 imputation methods. How well did the methods recover the missing values?  That is remove some data, check the % error on residuals for numeric data and check for bias and variance of the error.\n",
        "the distributions of the predictor variables?\n",
        ""
      ],
      "metadata": {
        "id": "Kuj0We2cRYBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "ZhHvCIwqProl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/ChaudharyAnshul/INFO6105_Assignments/main/Nifty50_Data/NIFTY50_all.csv\"\n",
        "data = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "u90l6NR3Re8f"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "84h2QmJ4Rhly",
        "outputId": "8ddcf5b1-506e-4f4c-bbe5-ddcbee82b7d2"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date      Symbol Series  Prev Close    Open     High    Low   Last  \\\n",
              "0  2007-11-27  MUNDRAPORT     EQ      440.00  770.00  1050.00  770.0  959.0   \n",
              "1  2007-11-28  MUNDRAPORT     EQ      962.90  984.00   990.00  874.0  885.0   \n",
              "2  2007-11-29  MUNDRAPORT     EQ      893.90  909.00   914.75  841.0  887.0   \n",
              "3  2007-11-30  MUNDRAPORT     EQ      884.20  890.00   958.00  890.0  929.0   \n",
              "4  2007-12-03  MUNDRAPORT     EQ      921.55  939.75   995.00  922.0  980.0   \n",
              "\n",
              "    Close    VWAP    Volume      Turnover  Trades  Deliverable Volume  \\\n",
              "0  962.90  984.72  27294366  2.687719e+15     NaN           9859619.0   \n",
              "1  893.90  941.38   4581338  4.312765e+14     NaN           1453278.0   \n",
              "2  884.20  888.09   5124121  4.550658e+14     NaN           1069678.0   \n",
              "3  921.55  929.17   4609762  4.283257e+14     NaN           1260913.0   \n",
              "4  969.30  965.65   2977470  2.875200e+14     NaN            816123.0   \n",
              "\n",
              "   %Deliverble  \n",
              "0       0.3612  \n",
              "1       0.3172  \n",
              "2       0.2088  \n",
              "3       0.2735  \n",
              "4       0.2741  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-291e9670-4b96-47db-ace3-4783d1414eca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Series</th>\n",
              "      <th>Prev Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>VWAP</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Turnover</th>\n",
              "      <th>Trades</th>\n",
              "      <th>Deliverable Volume</th>\n",
              "      <th>%Deliverble</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-11-27</td>\n",
              "      <td>MUNDRAPORT</td>\n",
              "      <td>EQ</td>\n",
              "      <td>440.00</td>\n",
              "      <td>770.00</td>\n",
              "      <td>1050.00</td>\n",
              "      <td>770.0</td>\n",
              "      <td>959.0</td>\n",
              "      <td>962.90</td>\n",
              "      <td>984.72</td>\n",
              "      <td>27294366</td>\n",
              "      <td>2.687719e+15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9859619.0</td>\n",
              "      <td>0.3612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-11-28</td>\n",
              "      <td>MUNDRAPORT</td>\n",
              "      <td>EQ</td>\n",
              "      <td>962.90</td>\n",
              "      <td>984.00</td>\n",
              "      <td>990.00</td>\n",
              "      <td>874.0</td>\n",
              "      <td>885.0</td>\n",
              "      <td>893.90</td>\n",
              "      <td>941.38</td>\n",
              "      <td>4581338</td>\n",
              "      <td>4.312765e+14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1453278.0</td>\n",
              "      <td>0.3172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-11-29</td>\n",
              "      <td>MUNDRAPORT</td>\n",
              "      <td>EQ</td>\n",
              "      <td>893.90</td>\n",
              "      <td>909.00</td>\n",
              "      <td>914.75</td>\n",
              "      <td>841.0</td>\n",
              "      <td>887.0</td>\n",
              "      <td>884.20</td>\n",
              "      <td>888.09</td>\n",
              "      <td>5124121</td>\n",
              "      <td>4.550658e+14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1069678.0</td>\n",
              "      <td>0.2088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-11-30</td>\n",
              "      <td>MUNDRAPORT</td>\n",
              "      <td>EQ</td>\n",
              "      <td>884.20</td>\n",
              "      <td>890.00</td>\n",
              "      <td>958.00</td>\n",
              "      <td>890.0</td>\n",
              "      <td>929.0</td>\n",
              "      <td>921.55</td>\n",
              "      <td>929.17</td>\n",
              "      <td>4609762</td>\n",
              "      <td>4.283257e+14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1260913.0</td>\n",
              "      <td>0.2735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-12-03</td>\n",
              "      <td>MUNDRAPORT</td>\n",
              "      <td>EQ</td>\n",
              "      <td>921.55</td>\n",
              "      <td>939.75</td>\n",
              "      <td>995.00</td>\n",
              "      <td>922.0</td>\n",
              "      <td>980.0</td>\n",
              "      <td>969.30</td>\n",
              "      <td>965.65</td>\n",
              "      <td>2977470</td>\n",
              "      <td>2.875200e+14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>816123.0</td>\n",
              "      <td>0.2741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-291e9670-4b96-47db-ace3-4783d1414eca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-291e9670-4b96-47db-ace3-4783d1414eca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-291e9670-4b96-47db-ace3-4783d1414eca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6c26827-c5c3-4f5a-86fc-50a96976e1f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6c26827-c5c3-4f5a-86fc-50a96976e1f2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6c26827-c5c3-4f5a-86fc-50a96976e1f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print all the Unique stock names\n",
        "symbol = data[\"Symbol\"].unique()\n",
        "print(symbol)\n",
        "print(\"Unique stock values: \", len(symbol))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz53V__iRi8u",
        "outputId": "e2748df2-a2cd-4a0b-d944-fb02d8b69e5c"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MUNDRAPORT' 'ADANIPORTS' 'ASIANPAINT' 'UTIBANK' 'AXISBANK' 'BAJAJ-AUTO'\n",
            " 'BAJAJFINSV' 'BAJAUTOFIN' 'BAJFINANCE' 'BHARTI' 'BHARTIARTL' 'BPCL'\n",
            " 'BRITANNIA' 'CIPLA' 'COALINDIA' 'DRREDDY' 'EICHERMOT' 'GAIL' 'GRASIM'\n",
            " 'HCLTECH' 'HDFC' 'HDFCBANK' 'HEROHONDA' 'HEROMOTOCO' 'HINDALC0'\n",
            " 'HINDALCO' 'HINDLEVER' 'HINDUNILVR' 'ICICIBANK' 'INDUSINDBK' 'INFOSYSTCH'\n",
            " 'INFY' 'IOC' 'ITC' 'JSWSTL' 'JSWSTEEL' 'KOTAKMAH' 'KOTAKBANK' 'LT' 'M&M'\n",
            " 'MARUTI' 'NESTLEIND' 'NTPC' 'ONGC' 'POWERGRID' 'RELIANCE' 'SBIN'\n",
            " 'SHREECEM' 'SUNPHARMA' 'TELCO' 'TATAMOTORS' 'TISCO' 'TATASTEEL' 'TCS'\n",
            " 'TECHM' 'TITAN' 'ULTRACEMCO' 'UNIPHOS' 'UPL' 'SESAGOA' 'SSLT' 'VEDL'\n",
            " 'WIPRO' 'ZEETELE' 'ZEEL']\n",
            "Unique stock values:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Some of the stock are renamed over time</h5>\n",
        "\n",
        "MUNDRAPORT -> ADANIPORTS\n",
        "\n",
        "BAJAUTOFIN -> BAJFINANCE\n",
        "\n",
        "BHARTI -> BHARTIARTL\n",
        "\n",
        "HINDLEVER -> HINDUNILVR\n",
        "\n",
        "JSWSTL -> JSWSTEEL\n",
        "\n",
        "KOTAKMAH -> KOTAKBANK\n",
        "\n",
        "TELCO -> TATAMOTORS\n",
        "\n",
        "TISCO -> TATASTEEL\n",
        "\n",
        "UNIPHOS -> UPL\n",
        "\n",
        "SESAGOA -> SESAGOA -> VEDL\n",
        "\n",
        "HINDALC0 -> HINDALCO"
      ],
      "metadata": {
        "id": "8lmyH_uYRxhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing the values\n",
        "replace = [\n",
        "    [\"MUNDRAPORT\",\"ADANIPORTS\"],\n",
        "    [\"BAJAUTOFIN\",\"BAJFINANCE\"],\n",
        "    [\"BHARTI\",\"BHARTIARTL\"],\n",
        "    [\"HINDLEVER\",\"HINDUNILVR\"],\n",
        "    [\"JSWSTL\",\"JSWSTEEL\"],\n",
        "    [\"KOTAKMAH\",\"KOTAKBANK\"],\n",
        "    [\"TELCO\",\"TATAMOTORS\"],\n",
        "    [\"TISCO\",\"TATASTEEL\"],\n",
        "    [\"SESAGOA\",\"VEDL\"],\n",
        "    [\"SESAGOA\",\"VEDL\"],\n",
        "    [\"HINDALC0\",\"HINDALCO\"],\n",
        "    [\"UNIPHOS\",\"UPL\"],\n",
        "]\n",
        "for i in replace:\n",
        "    data.loc[ data[\"Symbol\"] == i[0], \"Symbol\"] = i[1]"
      ],
      "metadata": {
        "id": "2zfBxWiuRlCt"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Symbol\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUUbmqlaR4jt",
        "outputId": "ca6f8be5-64ea-4e55-bea4-b818e3f5988a"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADANIPORTS', 'ASIANPAINT', 'UTIBANK', 'AXISBANK', 'BAJAJ-AUTO',\n",
              "       'BAJAJFINSV', 'BAJFINANCE', 'BHARTIARTL', 'BPCL', 'BRITANNIA',\n",
              "       'CIPLA', 'COALINDIA', 'DRREDDY', 'EICHERMOT', 'GAIL', 'GRASIM',\n",
              "       'HCLTECH', 'HDFC', 'HDFCBANK', 'HEROHONDA', 'HEROMOTOCO',\n",
              "       'HINDALCO', 'HINDUNILVR', 'ICICIBANK', 'INDUSINDBK', 'INFOSYSTCH',\n",
              "       'INFY', 'IOC', 'ITC', 'JSWSTEEL', 'KOTAKBANK', 'LT', 'M&M',\n",
              "       'MARUTI', 'NESTLEIND', 'NTPC', 'ONGC', 'POWERGRID', 'RELIANCE',\n",
              "       'SBIN', 'SHREECEM', 'SUNPHARMA', 'TATAMOTORS', 'TATASTEEL', 'TCS',\n",
              "       'TECHM', 'TITAN', 'ULTRACEMCO', 'UPL', 'VEDL', 'SSLT', 'WIPRO',\n",
              "       'ZEETELE', 'ZEEL'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the data can be categorized based on the \"Symbol\" since it contains all the different possible stock\n",
        "data = data.astype({'Symbol': 'category'})"
      ],
      "metadata": {
        "id": "VZICqZCRR6MJ"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert column date to type date\n",
        "data['Date'] = pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "KwjnwqZrR8GT"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnP3bjrgSHC8",
        "outputId": "98b78a5f-16dd-47a8-d8ef-b72083d94775"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 235192 entries, 0 to 235191\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count   Dtype         \n",
            "---  ------              --------------   -----         \n",
            " 0   Date                235192 non-null  datetime64[ns]\n",
            " 1   Symbol              235192 non-null  category      \n",
            " 2   Series              235192 non-null  object        \n",
            " 3   Prev Close          235192 non-null  float64       \n",
            " 4   Open                235192 non-null  float64       \n",
            " 5   High                235192 non-null  float64       \n",
            " 6   Low                 235192 non-null  float64       \n",
            " 7   Last                235192 non-null  float64       \n",
            " 8   Close               235192 non-null  float64       \n",
            " 9   VWAP                235192 non-null  float64       \n",
            " 10  Volume              235192 non-null  int64         \n",
            " 11  Turnover            235192 non-null  float64       \n",
            " 12  Trades              120344 non-null  float64       \n",
            " 13  Deliverable Volume  219115 non-null  float64       \n",
            " 14  %Deliverble         219115 non-null  float64       \n",
            "dtypes: category(1), datetime64[ns](1), float64(11), int64(1), object(1)\n",
            "memory usage: 25.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: What are the data types? (Only numeric and categorical)</h3>\n",
        "A: the data types are listed below\n",
        "\n",
        "* There are 11 columns  with numeric data 'Prev Close', 'Open', 'High', 'Low', 'Last',  'Close', 'VWAP', 'Volume', 'Turnover', 'Trades', 'Deliverable Volume', '%Deliverble'.\n",
        "* There is 1 category data 'Symbol'.\n",
        "* There are 1 datetime data 'Date'."
      ],
      "metadata": {
        "id": "7xBnyWvYSGdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding null values if any\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBh4FiiISLQ1",
        "outputId": "9473cdf5-3e7d-4835-878c-e57899a5e4b5"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                       0\n",
              "Symbol                     0\n",
              "Series                     0\n",
              "Prev Close                 0\n",
              "Open                       0\n",
              "High                       0\n",
              "Low                        0\n",
              "Last                       0\n",
              "Close                      0\n",
              "VWAP                       0\n",
              "Volume                     0\n",
              "Turnover                   0\n",
              "Trades                114848\n",
              "Deliverable Volume     16077\n",
              "%Deliverble            16077\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Are there missing values?</h3>\n",
        "A: There are NaN values present in the data, the dataset captured 0 as Null/NaN hence filling the null values with 0 for Trades, Deliverable Volume and %Deliverble.\n",
        "\n",
        "Explained below:\n",
        "\n",
        "<b>Number of Trades</b> can be 0 - It's very simple to understand that if the deal which is comprised of sellers and buyers is zero, the buyers and sellers for that trade aren't buying or selling.\n",
        "Volumes are always positive if not zero and can be represented as the number of trades per day for a commodity, stock, options, or future.\n",
        "\n",
        "<b>Deliverable Volume</b> can be 0 - In the context of stock trading and financial markets, \"deliverable volume\" typically refers to the number of shares of a particular stock that are traded and actually delivered to the buyer or seller during a trading session. It represents the number of shares that have changed ownership. There are some situations where deliverable volume might be very low, or zero for certain stocks.\n",
        "\n",
        "<b>%Deliverble</b> can be 0 - It is possible for the \"% Deliverable\" (percentage of shares that were delivered) of a stock to be zero or close to zero on a particular trading day. \"% Deliverable\" is a measure that indicates the proportion of shares traded for a particular stock on a given day that were actually delivered to the buyers' accounts.\n"
      ],
      "metadata": {
        "id": "fhhq8fQ5SkU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace null values with 0 based on the above explanation\n",
        "data[\"Trades\"].fillna(0, inplace = True)\n",
        "data[\"Deliverable Volume\"].fillna(0, inplace = True)\n",
        "data[\"%Deliverble\"].fillna(0, inplace = True)"
      ],
      "metadata": {
        "id": "5gsA3XcuSaNU"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if there is still any null values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXcEweE6SqEG",
        "outputId": "376ec847-853d-4495-dab2-75a74f37d1ab"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                  0\n",
              "Symbol                0\n",
              "Series                0\n",
              "Prev Close            0\n",
              "Open                  0\n",
              "High                  0\n",
              "Low                   0\n",
              "Last                  0\n",
              "Close                 0\n",
              "VWAP                  0\n",
              "Volume                0\n",
              "Turnover              0\n",
              "Trades                0\n",
              "Deliverable Volume    0\n",
              "%Deliverble           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Which independent variables have missing data? How much?</h3>\n",
        "A: There are no missing data present in the dataset, since in the above code the null values are already handled."
      ],
      "metadata": {
        "id": "l6VFotlIS3Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Checking distrubution of the data\n",
        "# density distrubution for entire data set\n",
        "plt.subplot(231)\n",
        "sns.histplot(data['Prev Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(232)\n",
        "sns.histplot(data['Open'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(233)\n",
        "sns.histplot(data['High'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(234)\n",
        "sns.histplot(data['Low'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(235)\n",
        "sns.histplot(data['Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(236)\n",
        "sns.histplot(data['VWAP'], kde=True, stat=\"density\", linewidth=0)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(10,10)"
      ],
      "metadata": {
        "id": "-ICflNDwSv2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "\n",
        "* All the distributions show similar distribution properties\n",
        "* All the distributions are right skewed, that means they are positively skewed\n",
        "\n",
        "Need to select individual stocks and verify the skewness of data, since different socks trade in different price range.\n",
        "\n"
      ],
      "metadata": {
        "id": "DExIKkOPTSpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting individual Stocks to carry forward the analysis\n",
        "\n",
        "# ADANIPORTS\n",
        "data_ap = data.loc[ data[\"Symbol\"] == \"ADANIPORTS\"]\n",
        "# HDFCBANK\n",
        "data_hb = data.loc[ data[\"Symbol\"] == \"HDFCBANK\"]"
      ],
      "metadata": {
        "id": "kJrSJ2amTLeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Columns since they are not important\n",
        "data_ap = data_ap.drop(labels=[\"Series\",\"Symbol\"], axis=1)\n",
        "data_hb = data_hb.drop(labels=[\"Series\",\"Symbol\"], axis=1)"
      ],
      "metadata": {
        "id": "AXCH8Yi9Th8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# density distrubution for ADANIPORTS\n",
        "plt.subplot(231)\n",
        "sns.histplot(data_ap['Prev Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(232)\n",
        "sns.histplot(data_ap['Open'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(233)\n",
        "sns.histplot(data_ap['High'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(234)\n",
        "sns.histplot(data_ap['Low'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(235)\n",
        "sns.histplot(data_ap['Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(236)\n",
        "sns.histplot(data_ap['VWAP'], kde=True, stat=\"density\", linewidth=0)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(10,10)"
      ],
      "metadata": {
        "id": "zhIOs4elUHSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Similar to above Inference</h5>\n",
        "\n",
        "* All the distributions show similar distribution properties\n",
        "* All the distributions are right skewed showing positive skewness\n"
      ],
      "metadata": {
        "id": "rO50pVYbUYkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# density distrubution for HDFCBANK\n",
        "plt.subplot(231)\n",
        "sns.histplot(data_hb['Prev Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(232)\n",
        "sns.histplot(data_hb['Open'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(233)\n",
        "sns.histplot(data_hb['High'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(234)\n",
        "sns.histplot(data_hb['Low'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(235)\n",
        "sns.histplot(data_hb['Close'], kde=True, stat=\"density\", linewidth=0)\n",
        "\n",
        "plt.subplot(236)\n",
        "sns.histplot(data_hb['VWAP'], kde=True, stat=\"density\", linewidth=0)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(10,10)"
      ],
      "metadata": {
        "id": "NMyxMWwdUTdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Inference:</h4>\n",
        "\n",
        "* All the distributions show similar distribution properties\n",
        "* All the distributions are right skewed showing positive skewness\n",
        "\n"
      ],
      "metadata": {
        "id": "SQJYnbqpUg4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: What are the likely distributions of the numeric variables?</h3>\n",
        "\n",
        "A: For the above density distributions it is observed that the distributions are right-skewed.\n"
      ],
      "metadata": {
        "id": "rMEvpkE-Uw59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: What are the distributions of the predictor variables?</h3>\n",
        "A: Predictor variables are identified below they are - [\"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\"]. As per the graph above we can see that the predictors are skewed towards right resulting in Positively skewed (right-skewed) distributions.\n"
      ],
      "metadata": {
        "id": "XmQxnZ2qUznl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the Ranges of the predictor variables and dependent variables for ADANIPORTS\n",
        "plt.figure(figsize=(20, 7))\n",
        "sns.boxplot(data=data_ap[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Close\", \"VWAP\"]])"
      ],
      "metadata": {
        "id": "eGiCSUuVUhax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Inference:</h5>\n",
        "\n",
        "Looking at the box plot above it can be inferred that the values are in the same range and there are outliers present in all the columns. Considering the fact that the data is for a stock it is possible that the price would have shot up which explains the outliers exceeding the maximum value.\"\n"
      ],
      "metadata": {
        "id": "r__xhfhvU7y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the Ranges of the predictor variables and dependent variables for HDFCBANKHDFCBANK\n",
        "plt.figure(figsize=(20, 7))\n",
        "sns.boxplot(data=data_hb[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Close\", \"VWAP\"]])"
      ],
      "metadata": {
        "id": "u6GiO8HWU3ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "\n",
        "Looking at the box plot above it can be inferred that the values are in the same range and no data transformation is required.\n"
      ],
      "metadata": {
        "id": "n18FH6jsVAZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Do the ranges of the predictor variables make sense?</h3>\n",
        "A: The range of dataset makes sense as all the variables have similar Min and Max. The values are within expected and reasonable range based on the nature of the variable.\n"
      ],
      "metadata": {
        "id": "lQsJSYcvVEc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Feature Selection Methods</h4>\n",
        "\n",
        "1. Correlation Coefficient\n",
        "2. SelectKBest\n",
        "3. f_regression\n",
        "\n",
        "\n",
        "Target variable is \"Close\""
      ],
      "metadata": {
        "id": "_4j1qE2zVIJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Method 1: Correlation Coefficient</h4>"
      ],
      "metadata": {
        "id": "VvD-WTAdVLKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix for Asianpaints\n",
        "corr = data_ap.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "7CZjlVg1U-e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix for HDFCBank\n",
        "corr = data_hb.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "Xl847TzRVO2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "Based on the above matrix \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\" are strongly correlated with the target variable. This indicates a significant relationship with the target.\n",
        "\n"
      ],
      "metadata": {
        "id": "j-0jYsP6VQjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting the dependent and independent variables\n",
        "X_ap,y_ap = data_ap.drop(labels=[\"Date\",\"Close\"], axis=1), data_ap[\"Close\"]\n",
        "X_hb,y_hb = data_hb.drop(labels=[\"Date\",\"Close\"], axis=1), data_hb[\"Close\"]"
      ],
      "metadata": {
        "id": "WYrc4J8-VTPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Method 2: SelectKBest</h4>"
      ],
      "metadata": {
        "id": "2fNh0crGVpn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selectKBest method\n",
        "# trying all possible values of K to get an idea of the most impotant variables\n",
        "for i in range(2,12):\n",
        "    selector_1 = SelectKBest(score_func=f_classif, k=i)\n",
        "    selector_2 = SelectKBest(score_func=f_classif, k=i)\n",
        "\n",
        "    selector_1.fit_transform(X_ap, y_ap)\n",
        "    selected_features_mask_1 = selector_1.get_support()\n",
        "\n",
        "    selector_2.fit_transform(X_hb, y_hb)\n",
        "    selected_features_mask_2 = selector_2.get_support()\n",
        "\n",
        "    print(\"for AsianPaints K = \",i)\n",
        "    print(\"selected values: \", [v for v, b in zip(X_hb.columns, selected_features_mask_1) if b == True ])\n",
        "\n",
        "    print(\"for HDFCBank K = \",i)\n",
        "    print(\"selected values: \", [v for v, b in zip(X_hb.columns, selected_features_mask_1) if b == True ])\n",
        ""
      ],
      "metadata": {
        "id": "9Jt4AthiVY5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>This shows based on the k values, all independent variables that affect the dependent variables</h5>"
      ],
      "metadata": {
        "id": "B9PEUhhmVu6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Method 3: f_regression</h4>"
      ],
      "metadata": {
        "id": "UpW_y1JLVw15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#f_regression method to identify all important variables\n",
        "f_scores_ap, p_values_ap = f_regression(X_ap, y_ap)\n",
        "\n",
        "print(\"f-scores and p-values for Asianpaints\")\n",
        "print(\"F-scores:\")\n",
        "print(list(zip(X_ap.columns, f_scores_ap)))\n",
        "print(\"p-values:\")\n",
        "print(list(zip(X_ap.columns, p_values_ap)))\n",
        "\n",
        "f_scores_hb, p_values_hb = f_regression(X_hb, y_hb)\n",
        "\n",
        "print(\"\\n\\nf-scores and p-values for HDFCBank\")\n",
        "print(\"F-scores:\")\n",
        "print(list(zip(X_hb.columns, f_scores_hb)))\n",
        "print(\"p-values:\")\n",
        "print(list(zip(X_hb.columns, p_values_hb)))"
      ],
      "metadata": {
        "id": "elozAdnRVrkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Smaller p-values indicate a stronger relationship between the feature and the target variable</h5>"
      ],
      "metadata": {
        "id": "L-ZNgc9cV37h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Which independent variables are useful to predict a target (dependent variable)? (Use at least three methods)</h3>\n",
        "A: Based on the 3 methods shown above it can observe that\n",
        "\n",
        "* heatmap: there are 6 independent variables that are more useful in prediction \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\".\n",
        "\n",
        "* SelectKBest: it can be observed that as we keep increasing the K value the variables based on importance are increased with K. We get the priority order of the features, but we still need some more information to find the main features.\n",
        "\n",
        "* f_regression: based on the p-values of the independent variables it can be observed that 6 features have p-value as 0, ('Prev Close', 0.0), ('Open', 0.0), ('High', 0.0), ('Low', 0.0), ('Last', 0.0), ('VWAP', 0.0)\n",
        "\n",
        "we can conclude based on the 3 results that 6 features are important in the prediction of Close Price.\n",
        "\n"
      ],
      "metadata": {
        "id": "0onrsj8JV7yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair plot to find relation between independent variables\n",
        "sns.pairplot(X_ap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6XMyFa7DS2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot above it can be observed that \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\" are highly correlated to eachother\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CntJE7hNTh1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: In the predictor variables independent of all the other predictor variables?</h3>\n",
        "A: From the heatmap and pair plot above we can observe that the predictor variables are Multicollinearity.\n",
        "\n",
        "Predictor: \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\".\n",
        "\n"
      ],
      "metadata": {
        "id": "_Tj73hFpV_jZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Which predictor variables are the most important?</h3>\n",
        "A: Based on the feature selection above following are the most imporant\n",
        "\n",
        "* \"Prev Close\"\n",
        "* \"Open\"\n",
        "* \"High\"\n",
        "* \"Low\"\n",
        "* \"Last\"\n",
        "* \"VWAP\""
      ],
      "metadata": {
        "id": "JZ5_x32QWCoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into training and testing for Asianpaints\n",
        "X_train_ap, X_test_ap, y_train_ap, y_test_ap = train_test_split(X_ap, y_ap, test_size=0.2, random_state=42)\n",
        "\n",
        "# split the data into training and testing for HDFCBank\n",
        "X_train_hb, X_test_hb, y_train_hb, y_test_hb = train_test_split(X_hb, y_hb, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "P06-ucmUVzDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the data to see the histogram for Asianpaints for Test and Train data\n",
        "for c in X_test_ap.columns:\n",
        "    plt.hist(X_train_ap[c], bins=10, alpha=0.5, label=\"Train Set\", color=\"darkgreen\")\n",
        "    plt.hist(X_test_ap[c], bins=10, alpha=0.5, label=\"Test Set\", color =\"red\")\n",
        "    plt.xlabel(c, size=14)\n",
        "    plt.ylabel(\"Count\", size=14)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"{} distribution\".format(c))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mRAzIX-0V3FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Inference:</h5>\n",
        "\n",
        "* By looking at the split of data it looks like data is properly distributed in the ratio of 80%:20% for train and test respectively\n",
        "* it looks like as we move towards the right on x-axis the split of train:test decreases."
      ],
      "metadata": {
        "id": "-2usfP8DWLkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the data to see the histogram for HDFCBank for test and train data\n",
        "for c in X_test_hb.columns:\n",
        "    plt.hist(X_train_hb[c], bins=10, alpha=0.5, label=\"Train Set\", color=\"darkgreen\")\n",
        "    plt.hist(X_test_hb[c], bins=10, alpha=0.5, label=\"Test Set\", color =\"red\")\n",
        "    plt.xlabel(c, size=14)\n",
        "    plt.ylabel(\"Count\", size=14)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(\"{} distribution\".format(c))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "j_44HQ9hWHSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>Inference:</h5>\n",
        "\n",
        "* By looking at the split of data it looks like data is properly distributed in the ratio of 80%:20% for train and test respectively\n",
        "* It looks like from the above split the data is split uniformly across all values."
      ],
      "metadata": {
        "id": "kjN50_cRWOnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Do the training and test sets have the same data?</h3>\n",
        "A: No, the test and train data dont have same data values. This is the stock price for each day so the chance of the open, close, high, low and vwap combined to be same between 2 days is nearing 0."
      ],
      "metadata": {
        "id": "S0dWxrPSWUVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Linear regression Model</h3>"
      ],
      "metadata": {
        "id": "74MaAq7bWWne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot with the data points for Asianpaints\n",
        "for i in X_ap:\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    sns.scatterplot(x=X_ap[i], y=y_ap, label='Data Points')\n",
        "\n",
        "    # Fit a linear regression line to the data\n",
        "    sns.regplot(x=X_ap[i], y=y_ap, ci=None, label='Linear Regression Line')\n",
        "    plt.xlabel(i)\n",
        "    plt.ylabel('Close')\n",
        "    plt.title('Linear Regression Plot')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ym2wSB5bWNdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "It can be observed that the 6 features we selected from feature selection show a linear relationship with the target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "568aZX8SWcLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Model Training</h3>\n",
        "Training a linear regression model for Asian paints and HDFCBank\n",
        "<h4>Training the model with features that impact the target value the most</h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "khcVvDKPWfCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep relavent columns after feature selection\n",
        "X_train_ap, X_test_ap = X_train_ap[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Last\", \"VWAP\"]], X_test_ap[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Last\", \"VWAP\"]]\n",
        "X_train_hb, X_test_hb = X_train_hb[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Last\", \"VWAP\"]], X_test_hb[[\"Prev Close\", \"Open\", \"High\", \"Low\", \"Last\", \"VWAP\"]]"
      ],
      "metadata": {
        "id": "68_rFv50WZLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model for Asianpaints\n",
        "model_ap = LinearRegression()\n",
        "# model for HDFCBank\n",
        "model_hb = LinearRegression()"
      ],
      "metadata": {
        "id": "lz62iTRSWhSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model with Asianpaints data\n",
        "model_ap.fit(X_train_ap, y_train_ap)"
      ],
      "metadata": {
        "id": "iRraEtHfWi4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model with HDFCBank data\n",
        "model_hb.fit(X_train_hb, y_train_hb)"
      ],
      "metadata": {
        "id": "D0DfnSXEWlVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict Asianpaint\n",
        "y_pred_ap = model_ap.predict(X_test_ap)"
      ],
      "metadata": {
        "id": "pVM0Vgr3WspJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_ap = r2_score(y_test_ap, y_pred_ap)\n",
        "print(\"R-squared:\", r2_ap)"
      ],
      "metadata": {
        "id": "raAiN5Y4Wukp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict HDFCBank\n",
        "y_pred_hb = model_hb.predict(X_test_hb)"
      ],
      "metadata": {
        "id": "2VWyzbkAWwMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_hb = r2_score(y_test_hb, y_pred_hb)\n",
        "print(\"R-squared:\", r2_hb)"
      ],
      "metadata": {
        "id": "qf_E8-RFWyJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "\n",
        "* The R-squared value is nearing 1 in both the cases\n",
        "* R-squared metric helps understand that the regression model is a good fit to the data,\n"
      ],
      "metadata": {
        "id": "CXhZ8no0W1UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Squared Error for Asianpaint model\n",
        "mse_ap = mean_squared_error(y_test_ap, y_pred_ap)\n",
        "print(\"Mean of Asian Paint data:\", y_test_ap.mean())\n",
        "print(\"Mean Squared Error:\", mse_ap)"
      ],
      "metadata": {
        "id": "GlCVWoTXWzaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Squared Error for HDFCBank model\n",
        "mse_hb = mean_squared_error(y_test_hb, y_pred_hb)\n",
        "print(\"Mean of HDFC Bank data:\", y_test_hb.mean())\n",
        "print(\"Mean Squared Error:\", mse_hb)"
      ],
      "metadata": {
        "id": "hrSEolRPW49t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference:</h4>\n",
        "\n",
        "* The mean squared error of both the model is significantly lower than their respected mean values indicating a good fit of model\n",
        "\n"
      ],
      "metadata": {
        "id": "UIWf12ZmW9EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Removing Outrliers</h4>"
      ],
      "metadata": {
        "id": "UV90GLaBm1aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning for Asianpaints\n",
        "# taking the z-score to find the outliers\n",
        "z_scores_ap = stats.zscore(y_train_ap)"
      ],
      "metadata": {
        "id": "17JFziTkikb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot to check the threshold value\n",
        "sns.boxplot(data = z_scores_ap.to_frame())"
      ],
      "metadata": {
        "id": "O69viXYCpNtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values above 2 are the outliers in the data"
      ],
      "metadata": {
        "id": "T34ZFRj2rDkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2"
      ],
      "metadata": {
        "id": "VopyYmM1pTS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows based on the threshold value\n",
        "X_train_ap_clean = X_train_ap.copy() # make copy\n",
        "X_train_ap_clean[\"Zscore\"] = z_scores_ap # add column\n",
        "X_train_ap_clean[\"Close\"] = y_train_ap # add column\n",
        "\n",
        "index_ap = X_train_ap_clean[ (X_train_ap_clean['Zscore'] > threshold) ].index # find the index to drop\n",
        "X_train_ap_clean.drop(index_ap , inplace=True) # drop rows\n",
        "\n",
        "# split features\n",
        "y_train_ap_clean = X_train_ap_clean[\"Close\"]\n",
        "X_train_ap_clean = X_train_ap_clean.drop([\"Zscore\", \"Close\"], axis=1)"
      ],
      "metadata": {
        "id": "Ox0H3aEWqQgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data Cleaning for  HDFCBank\n",
        "# taking the z-score to find the outliers\n",
        "z_scores_hb = stats.zscore(y_train_hb)"
      ],
      "metadata": {
        "id": "V5p990VarZaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot to check the threshold valu\n",
        "sns.boxplot(data=z_scores_hb.to_frame())"
      ],
      "metadata": {
        "id": "8fEAKLBVr8vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h5>As we can observe from the plot there are no outliers present in the data for HDFCBank</h5>"
      ],
      "metadata": {
        "id": "IM5QqpsIsJsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proceeding with training the model with clean data for Asianpaints"
      ],
      "metadata": {
        "id": "ODBfr_TKsM_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model for Asianpaints\n",
        "model_ap_new = LinearRegression()"
      ],
      "metadata": {
        "id": "owtaIVaosAPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model with HDFCBank data\n",
        "model_ap_new.fit(X_train_ap_clean, y_train_ap_clean)"
      ],
      "metadata": {
        "id": "HSaXpbd4sRWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict Asianpaint\n",
        "y_pred_ap_new = model_ap_new.predict(X_test_ap)"
      ],
      "metadata": {
        "id": "PmmrY3ABsTt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_ap_new = r2_score(y_test_ap, y_pred_ap_new)\n",
        "print(\"R-squared:\", r2_ap_new)"
      ],
      "metadata": {
        "id": "eqfdWRJtscOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Squared Error for Asianpaint model\n",
        "mse_ap_new = mean_squared_error(y_test_ap, y_pred_ap_new)\n",
        "print(\"Mean of Asian Paint data:\", y_test_ap.mean())\n",
        "print(\"Mean Squared Error:\", mse_ap_new)"
      ],
      "metadata": {
        "id": "Ebsi4Nj8sjkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Remove outliers and keep outliers (does if have an effect of the final predictive model)?</h3>\n",
        "A: After removing the outliers from the data there is not much change in the R-squared score of the predictive model.\n",
        "i think this was because the number of outliers in the data were very small compared to the actual dataset"
      ],
      "metadata": {
        "id": "O_62vhqps8eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h5>Removeing 1% 5% and 10% of the data randomly from the dataset</h5>**"
      ],
      "metadata": {
        "id": "xd0gMJq-7HTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_data = data_ap[\"Open\"] # original data\n",
        "# to remove data from row\n",
        "def RemoveData(per):\n",
        "    remove_per = per\n",
        "    num_rows = int(len(original_data) * remove_per) # number of row to delete\n",
        "    rows_delete = np.random.choice(original_data.index, num_rows, replace=False) # choose randomly\n",
        "    data_less = original_data.drop(rows_delete)  # drop random rows\n",
        "    print(\"Number of rows to populate \", per*100, \"% :\",num_rows)\n",
        "    return data_less, num_rows"
      ],
      "metadata": {
        "id": "VxJJ8JWcsxK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to add data to row and calculate error\n",
        "def FillDataAndCalculateError(data, value, num_rows, per):\n",
        "    data_less_df = data.to_frame()  # convert to frame\n",
        "    new_data = {\n",
        "        'Open': [value] * num_rows,\n",
        "    }\n",
        "    new_df = pd.DataFrame(new_data)\n",
        "    new_df = pd.concat([data_less_df, new_df]) # merge frame\n",
        "\n",
        "\n",
        "    # calculating Error Bias and Variance\n",
        "    residuals = original_data - new_df[\"Open\"]\n",
        "    percent_errors = np.abs(residuals / original_data) * 100\n",
        "    bias = np.mean(percent_errors)\n",
        "    variance = np.std(percent_errors)\n",
        "    print(\"Error for %\", per, \" (Bias): \", bias)\n",
        "    print(\"Error for %\", per, \" (Variance): \", variance)"
      ],
      "metadata": {
        "id": "Lbh4_TUP7MN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing 1% data\n",
        "remove_per = 0.01\n",
        "data_less_1, num_rows_1 = RemoveData(remove_per)\n",
        "\n",
        "# removing 5% data\n",
        "remove_per = 0.05\n",
        "data_less_5, num_rows_5 = RemoveData(remove_per)\n",
        "\n",
        "# removing 10% data\n",
        "remove_per = 0.1\n",
        "data_less_10, num_rows_10 = RemoveData(remove_per)\n",
        "\n",
        "#Added back mean of all the values\n",
        "FillDataAndCalculateError(data_less_1, float(data_less_1.to_frame().mean()), num_rows_1, 1)\n",
        "FillDataAndCalculateError(data_less_5, float(data_less_5.to_frame().mean()), num_rows_5, 5)\n",
        "FillDataAndCalculateError(data_less_10, float(data_less_10.to_frame().mean()), num_rows_10, 10)"
      ],
      "metadata": {
        "id": "J7Sr6l7cCju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing 1% data\n",
        "remove_per = 0.01\n",
        "data_less_1, num_rows_1 = RemoveData(remove_per)\n",
        "\n",
        "# removing 5% data\n",
        "remove_per = 0.05\n",
        "data_less_5, num_rows_5 = RemoveData(remove_per)\n",
        "\n",
        "# removing 10% data\n",
        "remove_per = 0.1\n",
        "data_less_10, num_rows_10 = RemoveData(remove_per)\n",
        "\n",
        "#Added back median of all the values\n",
        "FillDataAndCalculateError(data_less_1, float(data_less_1.to_frame().median()), num_rows_1, 1)\n",
        "FillDataAndCalculateError(data_less_5, float(data_less_5.to_frame().median()), num_rows_5, 5)\n",
        "FillDataAndCalculateError(data_less_10, float(data_less_10.to_frame().median()), num_rows_10, 10)"
      ],
      "metadata": {
        "id": "BZHSKzkUDAFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Inference</h4>\n",
        "There is low Bias and low variance when the missing value is filled by mean, median but as the missing values increases the bias and variance also increases.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qyy_pvRG7xSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Q: Remove 1%, 5%, and 10% of your data randomly and impute the values back using at least 3 imputation methods. How well did the methods recover the missing values?  That is remove some data, check the % error on residuals for numeric data and check for bias and variance of the error.</h3>\n",
        "A: The missing data was replaced by mean and median and it was observed that when the missing data percent is small bias and standard deviation of the error was small with increase in missing value the variance also increased"
      ],
      "metadata": {
        "id": "NQizx62ADhcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h2>Conclusion:</h2>\n",
        "\n",
        "*   The Above Dataset has both numeric and categorical data\n",
        "*   After Feature Selection it was observed that the independent variables useful to predict are \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\".\n",
        "*   None of the Independent variables were missing in the dataset, however there were some missing values in the data which were replaced by 0\n",
        "*   The Train and Test data are split in the ratio of 80%:20% and they donâ€™t have the same values\n",
        "*   The Predictor variables are Multicollinearity, i.e., they are highly related to each other\n",
        "*   \"Prev Close\", \"Open\", \"High\", \"Low\", Last\", \"VWAP\" are the most important predictor variables.\n",
        "*   All the variables have similar Min and Max. The values are within expected and reasonable range based on the nature of the variable.\n",
        "*   The Distribution of the predictor variables are right-skewed and have a positive skewed distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XoPxy80JH08c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>References :</h2>\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\n",
        "*   https://pandas.pydata.org/docs/reference/frame.html#dataframe\n",
        "*   https://github.com/aiskunks/YouTube/tree/main/A_Crash_Course_in_Statistical_Learning/ML_Data_Cleaning_and_Feature_Selection\n",
        "*   https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/\n",
        "*   Stack Overflow to get around errors - https://stackoverflow.com\n",
        "*   https://seaborn.pydata.org/\n",
        "*   https://matplotlib.org/\n",
        "*   https://github.com/nikbearbrown/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "byq56zCiKfSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) [2023] [Anshul Chaudhary]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS,\" WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n"
      ],
      "metadata": {
        "id": "6PIUViwaRs3y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cE2CxjNGSJxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}